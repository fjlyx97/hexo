---
title: 高并发系统设计
date: 2020-07-18 14:09:10
tags:
- linux
- 学习
- 并发
categories : "Linux"
---

> - 高并发系统设计笔记
> - 基于极客时间专栏

<!-- more-->


# 性能的度量指标
明确度量指标十分重要，单次响应时间没有意义，应当关注一段时间的性能是什么样的。依据一些统计方法计算出特征值，这些特征值可以反应在这段时间的性能情况。常用的指标如下：

## 平均值
这段时间响应时间相加，除以总数。这种方案敏感性较差，如果出现了慢请求，无法如实反映出实际情况

## 最大值
请求时间最长的值。和平均值相比，太过敏感。

## 分位值
分位值分为很多种，比如90分位，95分位，75分位。把这段响应时间从小到大排序，假设100个请求，排在第90位的响应时间就是90分位值。这种方案可以排除偶发的慢请求对数据的影响，很好的反应出这段时间的性能情况，分位值越大，对于慢请求的影响就越敏感。
- 分位值适合在时间段内，响应时间统计值来使用，在实际应用中也应用的最多。
- 通常描述：在每秒 1 万次的请求量下，响应时间 99 分位值在 10ms 以下。

## 分界点
从用户体验来看：**200ms**感受不到延时。**1s**，感受到延时，但是可以接收。之后等待时间越长，用户体验就越差。因此健康系统的99分位值应当控制在200ms以内。而不超过1s的请求占比要在99.99%以上。

# 高并发下的性能优化
## 提高系统的处理核心数
提高系统核心数可以提高性能，但是并不意味着无限制提高核心数就可以无限制提高性能。多核心数意味着资源争抢愈发严重。在某个临界点上继续增加并发进程数，反而会造成系统性能的下降，这就是**拐点模型**。

## 减少单次任务的响应时间
区分是CPU密集型还是IO密集型

### CPU密集型
需要大量的CPU运算，选用更高效的算法，或减少运算次数。可以通过Profile工具来找到消耗cpu时间更多的方法或者模块，如linux的perf,eBPF等

### IO密集型
IO密集型大部分操作都是等待IO完成，如磁盘IO，网络IO。解决方案：采用工具排查，一些开发语言甚至有对应的内存工具。另一类手段是通过监控来发现性能问题，对每个步骤进行分时统计，从而找到任务的消耗时间。

# 可用性度量
## MTBF（Mean Time Between Failure）
平均故障间隔，代表两次故障间隔时间，也就是系统正常运转的平均时间。这个时间越长，系统越稳定

## MTTR （Mean Time To Repair）
故障平均恢复时间。越短影响越小。

# 主从读写分离（数据库）
Mysql主从复制依赖binlog，即记录mysql上所有变化，并以二进制保存在磁盘日志文件上，这个过程一般是异步的。但是出于性能考虑，主库的写入流程不会等待主从同步完成后就返回。极端情况下如binlog还没刷新到磁盘，磁盘挂掉断电等，导致binlog丢失，会造成主从不一致。

- 无限制增加从库并不能完全抵抗大量的并发。随着从库增加，从库连上来的IO线程比较多，主库资源消耗比较高，同样受限于网络带宽。一般推荐一个主库挂3-5个从库

## 延时问题
有的时候从数据库查询不到信息，一段时间后又可以查询到信息。有可能是总从延时在作怪。所以把**从库落后时间**做个一个重要的指标进行监控和报警，正常的时间是在**毫秒级别**。

## 访问数据库问题
数据库采用主从方式之后，会出现多个数据库地址，并且需要区分写入操作和查询操作。因此业界引入**中间件**在解决数据库访问问题。

### 淘宝TDDL
以代码形式内嵌运行在应用程序内部，可以看成一种数据源代理，中间件将sql语句发给某个指定的数据源来处理，并将处理结果返回。
- 优点：简单易用，不用多余部署。
- 缺点：嵌入程序，更新困难，并且缺乏多语言支持。

### 单独部署代理层
阿里巴巴开源的Cobar，基于Cobar开发出来的Mycat等。这类代理层单独部署在独立的服务器上，业务代码如使用单一数据库一样使用它。

- 优点：独立部署，方便升级
- 缺点：Sql语句跨越两次网络，从应用->代理->数据源，性能有一定损耗

# 分库分表（数据库）
分库分表后，每个节点只保存部分的数据，这样可以减少单个数据库节点和单个数据表中存储的数据量，解决存储瓶颈和查询效率。

## （数据库）垂直拆分
对数据库竖着拆分，把数据库的表拆分到不同的数据库。核心思想：专库专用
```
------------------------------
|  用户       订单      物流  |
------------------------------
            ||                 
--------    ---------   ---------
| 用户 |    |  订单  |   | 物流  |
-------     ---------   ---------
```
- 这种方案偏常规，但是并不能直接解决业务量大量增多的场景。

## （数据库）水平拆分
1. 对某一个字段hash，比较适合实体表如用户表。对用户id进行hash，再对库数取余，即可分散到各个库上去。
2. 按照某一字段划分，如时间来划分。

## （表）垂直拆分和水平拆分
表的水平拆分和库的几乎一致，但是表的垂直拆分略有不同。表的垂直拆分是将字段进行分割到多表

## 对比
垂直拆分注重业务的相关性，水平拆分注重的是将单一数据表按某一种规则分到多个数据库和数据表中，关注数据的特点。

## 分库分表带来的问题
最大的问题是引入了分区键，查询的时候必须带上这个字段，才能找到数据所在的库和表，否则就只能向所有数据库和表发送查询指令，次数为：**库数x表数**。
1. 建议：性能没到瓶颈就尽量不做分库分表
2. 要做就一次做到位，如一次性做出16库64表，满足几年内的业务需求

# 发号器（数据库）
上文的分库分表，会带来一个问题就是全局唯一性的问题。

## 数据库主键要如何选择
依据数据库第二范式，数据库中的每一个表都需要有一个唯一主键，一般来说有两种方式。
1. 使用业务字段作为主键，如用户手机号，email，身份证号。但是大多数情况不适合用，如评论表很难找到一个字段标识唯一评论。用户表一个人可以拥有多个手机和email，一旦变更手机号或者email，就需要变更所有外键信息。身份证号同理，身份证号码位数变更，一样会引起巨大变动。
2. 使用生成的唯一ID作为主键。单库单表的情况，我们可以用自增字段作为ID，这样最简单，也最透明，但是分库分表后，使用自增字段就无法保证ID的全局唯一性了。

## 基于Snowflake算法搭建发号器
### UUID
UUID（统一唯一标识码），不依赖于第三方系统，性能可用性较好，但是如果用来数据库主键，会存在以下几点问题：
1. 生产的ID无序，不能单调递增，而数据库中ID可能有被用来做特殊用途，如作为分区键、排序的用途。
2. ID有序可以保障数据库写入性能，B+数底层是有序排列的，如果插入是递增ID，只需要把他加入尾部即可。
3. UUID不具备业务含义

## 雪花算法
Snowflake 的核心思想是将 64bit 的二进制数字分成若干部分，每一部分都存储有特定含义的数据，比如说时间戳、机器 ID、序列号等等，最终生成全局唯一的有序 ID。它的标准算法是这样的：
```
0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000
    |              毫秒级时间                    | |数据中心||机器|   |毫秒内计数|
```

### 问题
Snowflake的算法完全依赖于时间，如果时钟回拨的话，可能会生成重复的ID，因此解决方案有：
1. 关闭时间同步
2. 使用阿里云的时间服务器
3. 如果回拨时间很短，如5毫秒，就等待一会

如果请求量很小的话，会造成末位毫秒内计数始终为1，如果使用了分区的技术，会造成分配不均匀，因此解决方案有：
1. 时间戳记录的是秒而不是毫秒
2. 生成的序列号的起始号做一下随机，尽量均衡

## 部署
1. 嵌入业务代码，好处是不需要跨网络调用，性能会好一些，但是需要更多的机器ID来支撑业务（确保机器ID唯一，需要通过zookeeper分布式一致性组件来保证机器重启一定获得唯一的机器ID
2. 独立服务部署（发号器服务），缺点：多一次网络调用，但是内网调用性能损耗有限，并且机器ID可以写在配置文件中（量少）。微博美团都是使用独立服务部署，性能上单实例单cpu可以达到2万每秒

# 缓存
缓存不一定是代表把数据放于内存中存储。凡是位于速度相差较大的两种硬件之间，用于协调两者数据传输速度差异的结构，都可以称为缓存。
- 缓存命中率是我们缓存最重要的一个监控项。

## 缓存的不足
1. 缓存适合读多写少的场景，并且数据最好带**热点属性**，如果缺少了热点属性，缓存的效应就不明显了。
2. 缓存提升系统的整体复杂度，并且会有数据不一致的风险。如更新数据库成功，更新缓存失败，缓存中就会存在脏数据。通常我们会设置较短的过期期限，或者手动清理。
3. 需要评估内存，内存有限。

# 选择缓存的读写策略（重要）
针对不同场景，需要考虑不同的策略。并且需要考虑诸多因素，如缓存是否可能**被写入脏数据**，策略的**读写性能**如何，是否存在缓存的**命中率下降**

## 旁路策略（常用）
考虑如下场景：A请求将数据库id从20变21->B请求将数据库从21变22->B请求写入缓存->A请求写入缓存。这首和会造成更新丢失
- 解决方案：更新数据的时候（先），同时删除缓存（后），等待下次查询缓存时，重新从数据库中读取。**顺序不能调换**

最大的问题：当写入比较频繁时，缓存也会被清空的比较频繁，会对缓存的命中率造成一定的影响。